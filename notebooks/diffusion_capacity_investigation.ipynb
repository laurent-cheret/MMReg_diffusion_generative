{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diffusion Model Capacity Investigation\n",
    "\n",
    "Does a larger UNet improve diffusion quality? Test 3 model sizes on 20k CelebA latents.\n",
    "\n",
    "## Pipeline\n",
    "1. Setup + install dependencies\n",
    "2. Load CelebA + compute PCA\n",
    "3. Train Baseline + MM-Reg VAEs on full CelebA\n",
    "4. Encode all images to latents (cached)\n",
    "5. Train 6 diffusion models (3 sizes x 2 VAE variants) on 20k subset\n",
    "6. Compare results + generate samples\n",
    "\n",
    "## Training improvements\n",
    "- Gradient clipping (max_norm=1.0)\n",
    "- EMA weights (decay=0.9999)\n",
    "- Cosine LR schedule\n",
    "\n",
    "## UNet Variants\n",
    "| Variant | base_channels | channel_mult | num_res_blocks |\n",
    "|---------|--------------|--------------|----------------|\n",
    "| Small   | 128          | (1, 2, 4)    | 2              |\n",
    "| Medium  | 192          | (1, 2, 4)    | 2              |\n",
    "| Large   | 256          | (1, 2, 4, 4) | 2              |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone repository\n",
    "!rm -rf MMReg_diffusion_generative 2>/dev/null\n",
    "!git clone https://github.com/laurent-cheret/MMReg_diffusion_generative.git\n",
    "%cd MMReg_diffusion_generative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install -q torch torchvision diffusers transformers accelerate\n",
    "!pip install -q pyyaml tqdm scipy scikit-learn matplotlib\n",
    "!pip install -q datasets gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '.')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import copy\n",
    "import os\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"Device: {device}\")\n",
    "if device == 'cuda':\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_mem / 1e9:.1f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment configuration\n",
    "CONFIG = {\n",
    "    # Data\n",
    "    'data_root': './data',\n",
    "    'image_size': 128,\n",
    "    'batch_size': 64,\n",
    "\n",
    "    # PCA\n",
    "    'pca_components': 256,\n",
    "\n",
    "    # VAE Training (on full dataset, once)\n",
    "    'vae_epochs': 5,\n",
    "    'vae_lr': 1e-5,\n",
    "    'lambda_mm': 1.0,\n",
    "    'beta': 1e-6,\n",
    "\n",
    "    # Diffusion Training\n",
    "    'n_train': 20000,\n",
    "    'diffusion_epochs': 50,\n",
    "    'diffusion_lr': 1e-4,\n",
    "    'diffusion_timesteps': 1000,\n",
    "    'grad_clip': 1.0,\n",
    "    'ema_decay': 0.9999,\n",
    "}\n",
    "\n",
    "# UNet variants\n",
    "UNET_CONFIGS = {\n",
    "    'small': {\n",
    "        'base_channels': 128,\n",
    "        'channel_mult': (1, 2, 4),\n",
    "        'num_res_blocks': 2,\n",
    "    },\n",
    "    'medium': {\n",
    "        'base_channels': 192,\n",
    "        'channel_mult': (1, 2, 4),\n",
    "        'num_res_blocks': 2,\n",
    "    },\n",
    "    'large': {\n",
    "        'base_channels': 256,\n",
    "        'channel_mult': (1, 2, 4, 4),\n",
    "        'num_res_blocks': 2,\n",
    "    },\n",
    "}\n",
    "\n",
    "print(\"Configuration:\")\n",
    "for k, v in CONFIG.items():\n",
    "    print(f\"  {k}: {v}\")\n",
    "print(f\"\\nUNet variants: {list(UNET_CONFIGS.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load CelebA & Compute PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.dataset import (\n",
    "    get_celeba_dataset,\n",
    "    compute_pca_embeddings_celeba,\n",
    "    get_dataset_and_loader\n",
    ")\n",
    "\n",
    "# === CONFIGURATION: Choose your data source ===\n",
    "USE_HUGGINGFACE = True\n",
    "USE_DRIVE = False\n",
    "DRIVE_PATHS = {\n",
    "    'images_zip': '/content/drive/MyDrive/DATASETS/CelebA/img_align_celeba.zip',\n",
    "    'attr_file': '/content/drive/MyDrive/DATASETS/CelebA/list_attr_celeba.txt',\n",
    "    'partition_file': '/content/drive/MyDrive/DATASETS/CelebA/list_eval_partition.txt'\n",
    "}\n",
    "\n",
    "if USE_DRIVE:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "\n",
    "source = 'drive' if USE_DRIVE else 'huggingface'\n",
    "drive_paths = DRIVE_PATHS if USE_DRIVE else None\n",
    "\n",
    "# Load CelebA\n",
    "print(f\"Loading CelebA from {source}...\")\n",
    "train_dataset_fixed = get_celeba_dataset(\n",
    "    root=CONFIG['data_root'], split='train',\n",
    "    image_size=CONFIG['image_size'], fixed_transform=True,\n",
    "    source=source, drive_paths=drive_paths\n",
    ")\n",
    "val_dataset_fixed = get_celeba_dataset(\n",
    "    root=CONFIG['data_root'], split='val',\n",
    "    image_size=CONFIG['image_size'], fixed_transform=True,\n",
    "    source=source, drive_paths=drive_paths\n",
    ")\n",
    "\n",
    "total_train = len(train_dataset_fixed)\n",
    "print(f\"Train: {total_train}, Val: {len(val_dataset_fixed)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute PCA embeddings\n",
    "os.makedirs('./embeddings', exist_ok=True)\n",
    "\n",
    "print(\"Computing PCA embeddings for training set...\")\n",
    "train_pca = compute_pca_embeddings_celeba(\n",
    "    train_dataset_fixed, n_components=CONFIG['pca_components'], batch_size=256\n",
    ")\n",
    "torch.save(train_pca, './embeddings/celeba_train_pca.pt')\n",
    "\n",
    "print(\"Computing PCA embeddings for validation set...\")\n",
    "val_pca = compute_pca_embeddings_celeba(\n",
    "    val_dataset_fixed, n_components=CONFIG['pca_components'], batch_size=256\n",
    ")\n",
    "torch.save(val_pca, './embeddings/celeba_val_pca.pt')\n",
    "\n",
    "print(f\"Train PCA: {train_pca.shape}, Val PCA: {val_pca.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train VAEs on Full CelebA\n",
    "\n",
    "### 3.1 Baseline VAE (no MM-Reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.vae_wrapper import load_vae\n",
    "from src.models.losses import VAELoss\n",
    "from src.trainer import MMRegTrainer\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"TRAINING BASELINE VAE (no MM-Reg) on full CelebA\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "vae_baseline = load_vae(device=device)\n",
    "loss_baseline = VAELoss(lambda_mm=0.0, beta=CONFIG['beta'])\n",
    "\n",
    "train_dataset_base, train_loader_base = get_dataset_and_loader(\n",
    "    dataset_name='celeba', root=CONFIG['data_root'], split='train',\n",
    "    image_size=CONFIG['image_size'], batch_size=CONFIG['batch_size'],\n",
    "    num_workers=2, pca_embeddings_path='./embeddings/celeba_train_pca.pt',\n",
    "    celeba_source=source, celeba_drive_paths=drive_paths\n",
    ")\n",
    "val_dataset_base, val_loader_base = get_dataset_and_loader(\n",
    "    dataset_name='celeba', root=CONFIG['data_root'], split='val',\n",
    "    image_size=CONFIG['image_size'], batch_size=CONFIG['batch_size'],\n",
    "    num_workers=2, pca_embeddings_path='./embeddings/celeba_val_pca.pt',\n",
    "    celeba_source=source, celeba_drive_paths=drive_paths\n",
    ")\n",
    "\n",
    "optimizer_baseline = torch.optim.AdamW(vae_baseline.parameters(), lr=CONFIG['vae_lr'])\n",
    "\n",
    "trainer_baseline = MMRegTrainer(\n",
    "    vae=vae_baseline, loss_fn=loss_baseline, optimizer=optimizer_baseline,\n",
    "    train_loader=train_loader_base, val_loader=val_loader_base,\n",
    "    device=device, save_dir='./checkpoints/capacity_baseline_vae'\n",
    ")\n",
    "trainer_baseline.train(num_epochs=CONFIG['vae_epochs'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 MM-Reg VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"TRAINING MM-REG VAE on full CelebA\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "vae_mmreg = load_vae(device=device)\n",
    "loss_mmreg = VAELoss(\n",
    "    lambda_mm=CONFIG['lambda_mm'], beta=CONFIG['beta'], mm_variant='correlation'\n",
    ")\n",
    "\n",
    "train_dataset_mm, train_loader_mm = get_dataset_and_loader(\n",
    "    dataset_name='celeba', root=CONFIG['data_root'], split='train',\n",
    "    image_size=CONFIG['image_size'], batch_size=CONFIG['batch_size'],\n",
    "    num_workers=2, pca_embeddings_path='./embeddings/celeba_train_pca.pt',\n",
    "    celeba_source=source, celeba_drive_paths=drive_paths\n",
    ")\n",
    "val_dataset_mm, val_loader_mm = get_dataset_and_loader(\n",
    "    dataset_name='celeba', root=CONFIG['data_root'], split='val',\n",
    "    image_size=CONFIG['image_size'], batch_size=CONFIG['batch_size'],\n",
    "    num_workers=2, pca_embeddings_path='./embeddings/celeba_val_pca.pt',\n",
    "    celeba_source=source, celeba_drive_paths=drive_paths\n",
    ")\n",
    "\n",
    "optimizer_mmreg = torch.optim.AdamW(vae_mmreg.parameters(), lr=CONFIG['vae_lr'])\n",
    "\n",
    "trainer_mmreg = MMRegTrainer(\n",
    "    vae=vae_mmreg, loss_fn=loss_mmreg, optimizer=optimizer_mmreg,\n",
    "    train_loader=train_loader_mm, val_loader=val_loader_mm,\n",
    "    device=device, save_dir='./checkpoints/capacity_mmreg_vae'\n",
    ")\n",
    "trainer_mmreg.train(num_epochs=CONFIG['vae_epochs'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Evaluate VAEs & Encode Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.losses import pairwise_distances, get_upper_triangular\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "def quick_evaluate(vae, val_loader, val_pca, name):\n",
    "    \"\"\"Quick VAE evaluation: recon MSE + Pearson correlation.\"\"\"\n",
    "    vae.eval()\n",
    "    all_latents = []\n",
    "    total_recon = 0\n",
    "    num_samples = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(val_loader, desc=f\"Eval {name}\"):\n",
    "            images = batch[0].to(device)\n",
    "            outputs = vae(images, sample=False)\n",
    "            total_recon += ((outputs['x_recon'] - images) ** 2).mean().item() * images.shape[0]\n",
    "            num_samples += images.shape[0]\n",
    "            all_latents.append(outputs['latent_flat'].cpu())\n",
    "\n",
    "    all_latents = torch.cat(all_latents, dim=0)\n",
    "    n = min(500, len(all_latents))\n",
    "    D_lat = pairwise_distances(all_latents[:n])\n",
    "    D_pca = pairwise_distances(val_pca[:n])\n",
    "    d_lat = get_upper_triangular(D_lat).numpy()\n",
    "    d_pca = get_upper_triangular(D_pca).numpy()\n",
    "    pearson_val, _ = pearsonr(d_lat, d_pca)\n",
    "\n",
    "    recon_mse = total_recon / num_samples\n",
    "    print(f\"{name}: Recon MSE={recon_mse:.6f}, Pearson={pearson_val:.4f}\")\n",
    "    return {'recon_mse': recon_mse, 'pearson': pearson_val}\n",
    "\n",
    "print(\"\\nVAE Evaluation (on full val set):\")\n",
    "vae_results_baseline = quick_evaluate(vae_baseline, val_loader_base, val_pca, \"Baseline\")\n",
    "vae_results_mmreg = quick_evaluate(vae_mmreg, val_loader_mm, val_pca, \"MM-Reg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.diffusion_trainer import encode_dataset, LatentDataset\n",
    "\n",
    "# Simple dataloaders for encoding (no PCA wrapper)\n",
    "train_loader_simple = DataLoader(\n",
    "    train_dataset_fixed, batch_size=CONFIG['batch_size'],\n",
    "    shuffle=False, num_workers=2\n",
    ")\n",
    "val_loader_simple = DataLoader(\n",
    "    val_dataset_fixed, batch_size=CONFIG['batch_size'],\n",
    "    shuffle=False, num_workers=2\n",
    ")\n",
    "\n",
    "print(\"Encoding full dataset with Baseline VAE...\")\n",
    "train_latents_baseline = encode_dataset(vae_baseline, train_loader_simple, device)\n",
    "val_latents_baseline = encode_dataset(vae_baseline, val_loader_simple, device)\n",
    "print(f\"Baseline latents - Train: {train_latents_baseline.shape}, Val: {val_latents_baseline.shape}\")\n",
    "\n",
    "print(\"\\nEncoding full dataset with MM-Reg VAE...\")\n",
    "train_latents_mmreg = encode_dataset(vae_mmreg, train_loader_simple, device)\n",
    "val_latents_mmreg = encode_dataset(vae_mmreg, val_loader_simple, device)\n",
    "print(f\"MM-Reg latents - Train: {train_latents_mmreg.shape}, Val: {val_latents_mmreg.shape}\")\n",
    "\n",
    "# Save for potential reuse\n",
    "torch.save(train_latents_baseline, './embeddings/train_latents_baseline.pt')\n",
    "torch.save(val_latents_baseline, './embeddings/val_latents_baseline.pt')\n",
    "torch.save(train_latents_mmreg, './embeddings/train_latents_mmreg.pt')\n",
    "torch.save(val_latents_mmreg, './embeddings/val_latents_mmreg.pt')\n",
    "print(\"\\nLatents cached to ./embeddings/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Diffusion Capacity Experiment\n",
    "\n",
    "Train 3 UNet sizes x 2 VAE variants = 6 runs on 20k samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.diffusion import SimpleUNet, GaussianDiffusion\n",
    "\n",
    "# Subsample 20k training latents\n",
    "N_TRAIN = CONFIG['n_train']\n",
    "sub_train_baseline = train_latents_baseline[:N_TRAIN]\n",
    "sub_train_mmreg = train_latents_mmreg[:N_TRAIN]\n",
    "latent_size = sub_train_baseline.shape[2]\n",
    "\n",
    "print(f\"Training on {N_TRAIN:,} samples, {CONFIG['diffusion_epochs']} epochs\")\n",
    "print(f\"Latent size: {latent_size}x{latent_size}\")\n",
    "print(f\"Training improvements: grad_clip={CONFIG['grad_clip']}, EMA={CONFIG['ema_decay']}, cosine LR\")\n",
    "\n",
    "# Count params for each config\n",
    "print(f\"\\nUNet variants:\")\n",
    "for name, cfg in UNET_CONFIGS.items():\n",
    "    tmp = SimpleUNet(in_channels=4, **cfg)\n",
    "    n_params = sum(p.numel() for p in tmp.parameters())\n",
    "    print(f\"  {name:>6}: {n_params/1e6:.1f}M params  (base={cfg['base_channels']}, mult={cfg['channel_mult']})\")\n",
    "    del tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_ema(ema_model, model, decay=0.9999):\n",
    "    \"\"\"Update EMA model weights.\"\"\"\n",
    "    with torch.no_grad():\n",
    "        for ema_p, p in zip(ema_model.parameters(), model.parameters()):\n",
    "            ema_p.data.mul_(decay).add_(p.data, alpha=1 - decay)\n",
    "\n",
    "\n",
    "def train_diffusion(train_latents, val_latents, unet_config, name):\n",
    "    \"\"\"\n",
    "    Train a diffusion model with EMA, gradient clipping, cosine LR.\n",
    "    Returns: dict with results.\n",
    "    \"\"\"\n",
    "    save_dir = Path(f'./checkpoints/capacity_{name}')\n",
    "    save_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    epochs = CONFIG['diffusion_epochs']\n",
    "    lr = CONFIG['diffusion_lr']\n",
    "    batch_size = CONFIG['batch_size']\n",
    "    grad_clip = CONFIG['grad_clip']\n",
    "    ema_decay = CONFIG['ema_decay']\n",
    "    timesteps = CONFIG['diffusion_timesteps']\n",
    "\n",
    "    # Create model\n",
    "    diffusion = GaussianDiffusion(num_timesteps=timesteps, device=device)\n",
    "    unet = SimpleUNet(in_channels=4, **unet_config).to(device)\n",
    "    ema = copy.deepcopy(unet)\n",
    "    for p in ema.parameters():\n",
    "        p.requires_grad = False\n",
    "\n",
    "    n_params = sum(p.numel() for p in unet.parameters())\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Training: {name} ({n_params/1e6:.1f}M params)\")\n",
    "    print(f\"{'='*60}\")\n",
    "\n",
    "    # Optimizer + scheduler\n",
    "    optimizer = torch.optim.AdamW(unet.parameters(), lr=lr)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
    "\n",
    "    # Dataloaders\n",
    "    train_loader = DataLoader(\n",
    "        LatentDataset(train_latents), batch_size=batch_size,\n",
    "        shuffle=True, num_workers=0, pin_memory=True\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        LatentDataset(val_latents), batch_size=batch_size,\n",
    "        shuffle=False, num_workers=0\n",
    "    )\n",
    "\n",
    "    train_history = []\n",
    "    val_history = []\n",
    "    best_val_loss = float('inf')\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # --- Train ---\n",
    "        unet.train()\n",
    "        total_loss = 0\n",
    "        num_batches = 0\n",
    "\n",
    "        for latents in train_loader:\n",
    "            latents = latents.to(device)\n",
    "            bs = latents.shape[0]\n",
    "            t = torch.randint(0, timesteps, (bs,), device=device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss = diffusion.p_losses(unet, latents, t)\n",
    "            loss.backward()\n",
    "\n",
    "            torch.nn.utils.clip_grad_norm_(unet.parameters(), max_norm=grad_clip)\n",
    "            optimizer.step()\n",
    "            update_ema(ema, unet, ema_decay)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            num_batches += 1\n",
    "\n",
    "        scheduler.step()\n",
    "        train_loss = total_loss / num_batches\n",
    "        train_history.append(train_loss)\n",
    "\n",
    "        # --- Validate (using EMA model) ---\n",
    "        ema.eval()\n",
    "        val_total = 0\n",
    "        val_batches = 0\n",
    "        with torch.no_grad():\n",
    "            for latents in val_loader:\n",
    "                latents = latents.to(device)\n",
    "                bs = latents.shape[0]\n",
    "                t = torch.randint(0, timesteps, (bs,), device=device)\n",
    "                loss = diffusion.p_losses(ema, latents, t)\n",
    "                val_total += loss.item()\n",
    "                val_batches += 1\n",
    "\n",
    "        val_loss = val_total / val_batches\n",
    "        val_history.append(val_loss)\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save({'model_state_dict': ema.state_dict()}, save_dir / 'best.pt')\n",
    "\n",
    "        if epoch % 10 == 0 or epoch == epochs - 1:\n",
    "            lr_now = scheduler.get_last_lr()[0]\n",
    "            print(f\"  Epoch {epoch:3d}: train={train_loss:.6f}  val={val_loss:.6f}  lr={lr_now:.2e}\")\n",
    "\n",
    "    print(f\"  Best val loss: {best_val_loss:.6f}\")\n",
    "\n",
    "    # Free training model, keep EMA\n",
    "    del unet, optimizer, scheduler\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    return {\n",
    "        'diffusion': diffusion,\n",
    "        'ema_model': ema,\n",
    "        'train_history': train_history,\n",
    "        'val_history': val_history,\n",
    "        'best_val_loss': best_val_loss,\n",
    "        'n_params': n_params,\n",
    "        'config': unet_config,\n",
    "        'save_dir': save_dir,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run all 6 experiments\n",
    "results = {}\n",
    "\n",
    "for size_name, unet_cfg in UNET_CONFIGS.items():\n",
    "    # Baseline\n",
    "    key_base = f'{size_name}_baseline'\n",
    "    results[key_base] = train_diffusion(\n",
    "        sub_train_baseline, val_latents_baseline,\n",
    "        unet_cfg, key_base\n",
    "    )\n",
    "\n",
    "    # MM-Reg\n",
    "    key_mm = f'{size_name}_mmreg'\n",
    "    results[key_mm] = train_diffusion(\n",
    "        sub_train_mmreg, val_latents_mmreg,\n",
    "        unet_cfg, key_mm\n",
    "    )\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ALL TRAINING COMPLETE\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results table\n",
    "print(f\"{'Model':>16} | {'Params':>8} | {'Base Val':>10} | {'MMReg Val':>10} | {'Improv.':>8}\")\n",
    "print(\"-\" * 65)\n",
    "\n",
    "for size_name in UNET_CONFIGS:\n",
    "    base_val = results[f'{size_name}_baseline']['best_val_loss']\n",
    "    mm_val = results[f'{size_name}_mmreg']['best_val_loss']\n",
    "    n_params = results[f'{size_name}_baseline']['n_params']\n",
    "    improvement = (base_val - mm_val) / base_val * 100\n",
    "    print(f\"{size_name:>16} | {n_params/1e6:>7.1f}M | {base_val:>10.6f} | {mm_val:>10.6f} | {improvement:>7.1f}%\")\n",
    "\n",
    "print(f\"\\nBaseline improvement (small -> large): \"\n",
    "      f\"{results['small_baseline']['best_val_loss']:.6f} -> {results['large_baseline']['best_val_loss']:.6f} \"\n",
    "      f\"({(results['small_baseline']['best_val_loss'] - results['large_baseline']['best_val_loss']) / results['small_baseline']['best_val_loss'] * 100:.1f}%)\")\n",
    "print(f\"MM-Reg improvement (small -> large): \"\n",
    "      f\"{results['small_mmreg']['best_val_loss']:.6f} -> {results['large_mmreg']['best_val_loss']:.6f} \"\n",
    "      f\"({(results['small_mmreg']['best_val_loss'] - results['large_mmreg']['best_val_loss']) / results['small_mmreg']['best_val_loss'] * 100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot 1: Training curves - all 6 runs\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5), sharey=True)\n",
    "\n",
    "for i, size_name in enumerate(UNET_CONFIGS):\n",
    "    ax = axes[i]\n",
    "    n_params = results[f'{size_name}_baseline']['n_params']\n",
    "\n",
    "    ax.plot(results[f'{size_name}_baseline']['val_history'], 'b-', label='Baseline', alpha=0.8, linewidth=1.5)\n",
    "    ax.plot(results[f'{size_name}_mmreg']['val_history'], 'r-', label='MM-Reg', alpha=0.8, linewidth=1.5)\n",
    "\n",
    "    ax.set_title(f'{size_name.capitalize()} ({n_params/1e6:.1f}M)', fontsize=13)\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.legend(fontsize=10)\n",
    "    if i == 0:\n",
    "        ax.set_ylabel('Val Loss (EMA)')\n",
    "\n",
    "plt.suptitle(f'Diffusion Val Loss by Model Size ({N_TRAIN//1000}k samples)', fontsize=14, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.savefig('./checkpoints/capacity_val_curves.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot 2: Best val loss vs model size\n",
    "sizes = list(UNET_CONFIGS.keys())\n",
    "params = [results[f'{s}_baseline']['n_params'] / 1e6 for s in sizes]\n",
    "base_vals = [results[f'{s}_baseline']['best_val_loss'] for s in sizes]\n",
    "mm_vals = [results[f'{s}_mmreg']['best_val_loss'] for s in sizes]\n",
    "improvements = [(b - m) / b * 100 for b, m in zip(base_vals, mm_vals)]\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(13, 5))\n",
    "\n",
    "# Left: val loss vs params\n",
    "axes[0].plot(params, base_vals, 'bo-', label='Baseline', markersize=10, linewidth=2)\n",
    "axes[0].plot(params, mm_vals, 'rs-', label='MM-Reg', markersize=10, linewidth=2)\n",
    "axes[0].set_xlabel('Model Parameters (M)', fontsize=12)\n",
    "axes[0].set_ylabel('Best Val Loss', fontsize=12)\n",
    "axes[0].set_title('Diffusion Quality vs Model Capacity', fontsize=13)\n",
    "axes[0].legend(fontsize=11)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "for j, s in enumerate(sizes):\n",
    "    axes[0].annotate(s, (params[j], base_vals[j]), textcoords='offset points',\n",
    "                     xytext=(0, 10), ha='center', fontsize=9)\n",
    "\n",
    "# Right: MM-Reg improvement % by size\n",
    "x = range(len(sizes))\n",
    "axes[1].bar(x, improvements, color=['#2ecc71', '#27ae60', '#1e8449'], alpha=0.8)\n",
    "axes[1].set_xlabel('Model Size', fontsize=12)\n",
    "axes[1].set_ylabel('MM-Reg Improvement (%)', fontsize=12)\n",
    "axes[1].set_title('MM-Reg Advantage by Model Capacity', fontsize=13)\n",
    "axes[1].set_xticks(x)\n",
    "axes[1].set_xticklabels([f'{s}\\n({p:.0f}M)' for s, p in zip(sizes, params)])\n",
    "axes[1].grid(True, alpha=0.3, axis='y')\n",
    "for j, v in enumerate(improvements):\n",
    "    axes[1].text(j, v + 0.5, f'{v:.1f}%', ha='center', fontsize=11, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('./checkpoints/capacity_comparison.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Generate Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_and_plot(vae, latents, title, save_path):\n",
    "    vae.eval()\n",
    "    with torch.no_grad():\n",
    "        images = vae.decode(latents.to(device))\n",
    "    fig, axes = plt.subplots(2, 8, figsize=(16, 4))\n",
    "    fig.suptitle(title, fontsize=14)\n",
    "    for i in range(16):\n",
    "        img = images[i].cpu().permute(1, 2, 0).numpy()\n",
    "        img = ((img + 1) / 2).clip(0, 1)\n",
    "        axes[i // 8, i % 8].imshow(img)\n",
    "        axes[i // 8, i % 8].axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "# Generate with each model size for comparison\n",
    "latent_shape = (16, 4, latent_size, latent_size)\n",
    "\n",
    "for size_name in UNET_CONFIGS:\n",
    "    print(f\"\\n--- Generating with {size_name} model ---\")\n",
    "\n",
    "    diff = results[f'{size_name}_mmreg']['diffusion']\n",
    "\n",
    "    ema_mm = SimpleUNet(in_channels=4, **UNET_CONFIGS[size_name]).to(device)\n",
    "    ckpt = torch.load(f'./checkpoints/capacity_{size_name}_mmreg/best.pt', map_location=device)\n",
    "    ema_mm.load_state_dict(ckpt['model_state_dict'])\n",
    "\n",
    "    gen_latents = diff.sample(ema_mm, latent_shape, progress=True)\n",
    "\n",
    "    n_params = results[f'{size_name}_mmreg']['n_params']\n",
    "    decode_and_plot(\n",
    "        vae_mmreg, gen_latents,\n",
    "        f'MM-Reg {size_name.capitalize()} ({n_params/1e6:.0f}M params)',\n",
    "        f'./checkpoints/capacity_samples_{size_name}_mmreg.png'\n",
    "    )\n",
    "\n",
    "    del ema_mm, gen_latents\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_python(val):\n",
    "    if hasattr(val, 'item'):\n",
    "        return val.item()\n",
    "    return float(val)\n",
    "\n",
    "summary = {\n",
    "    'experiment': 'diffusion_capacity_investigation',\n",
    "    'n_train': CONFIG['n_train'],\n",
    "    'epochs': CONFIG['diffusion_epochs'],\n",
    "    'improvements': ['gradient_clipping', 'ema', 'cosine_lr'],\n",
    "    'vae_results': {\n",
    "        'baseline': {k: to_python(v) for k, v in vae_results_baseline.items()},\n",
    "        'mmreg': {k: to_python(v) for k, v in vae_results_mmreg.items()}\n",
    "    },\n",
    "    'diffusion_results': {}\n",
    "}\n",
    "\n",
    "for size_name in UNET_CONFIGS:\n",
    "    base_val = results[f'{size_name}_baseline']['best_val_loss']\n",
    "    mm_val = results[f'{size_name}_mmreg']['best_val_loss']\n",
    "    summary['diffusion_results'][size_name] = {\n",
    "        'n_params': results[f'{size_name}_baseline']['n_params'],\n",
    "        'config': {k: list(v) if isinstance(v, tuple) else v for k, v in UNET_CONFIGS[size_name].items()},\n",
    "        'baseline_best_val': to_python(base_val),\n",
    "        'mmreg_best_val': to_python(mm_val),\n",
    "        'improvement_pct': to_python((base_val - mm_val) / base_val * 100),\n",
    "    }\n",
    "\n",
    "with open('./checkpoints/capacity_investigation_summary.json', 'w') as f:\n",
    "    json.dump(summary, f, indent=2)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"CAPACITY INVESTIGATION SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\\nVAE (trained on full dataset):\")\n",
    "print(f\"  Baseline: Recon MSE={vae_results_baseline['recon_mse']:.6f}, Pearson={vae_results_baseline['pearson']:.4f}\")\n",
    "print(f\"  MM-Reg:   Recon MSE={vae_results_mmreg['recon_mse']:.6f}, Pearson={vae_results_mmreg['pearson']:.4f}\")\n",
    "\n",
    "print(f\"\\nDiffusion ({CONFIG['n_train']//1000}k samples, {CONFIG['diffusion_epochs']} epochs):\")\n",
    "print(f\"Training: grad_clip={CONFIG['grad_clip']}, EMA={CONFIG['ema_decay']}, cosine LR\")\n",
    "print(f\"\\n{'Model':>8} | {'Params':>8} | {'Base Val':>10} | {'MMReg Val':>10} | {'Improv':>7} | {'Base Drop':>10}\")\n",
    "print(\"-\" * 72)\n",
    "\n",
    "small_base = results['small_baseline']['best_val_loss']\n",
    "\n",
    "for size_name in UNET_CONFIGS:\n",
    "    base_val = results[f'{size_name}_baseline']['best_val_loss']\n",
    "    mm_val = results[f'{size_name}_mmreg']['best_val_loss']\n",
    "    n_params = results[f'{size_name}_baseline']['n_params']\n",
    "    improv = (base_val - mm_val) / base_val * 100\n",
    "    base_drop = (small_base - base_val) / small_base * 100\n",
    "    print(f\"{size_name:>8} | {n_params/1e6:>7.1f}M | {base_val:>10.6f} | {mm_val:>10.6f} | {improv:>6.1f}% | {base_drop:>+9.1f}%\")\n",
    "\n",
    "print(f\"\\nResults saved to ./checkpoints/capacity_investigation_summary.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
