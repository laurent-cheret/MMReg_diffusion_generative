{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MM-Reg: Manifold-Matching Regularization for VAE\n",
    "\n",
    "This notebook tests and trains MM-Reg VAE on Colab.\n",
    "\n",
    "**Steps:**\n",
    "1. Setup & Install dependencies\n",
    "2. Test components (loss, reference model, VAE)\n",
    "3. Train baseline VAE\n",
    "4. Train MM-Reg VAE\n",
    "5. Evaluate and compare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone the repository (replace with your GitHub URL)\n",
    "!git clone https://github.com/YOUR_USERNAME/MMReg_diffusion_generative.git\n",
    "%cd MMReg_diffusion_generative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install -q torch torchvision diffusers transformers accelerate\n",
    "!pip install -q pyyaml tqdm scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '.')\n",
    "\n",
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Test Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test MM-Reg Loss\n",
    "from src.models.losses import MMRegLoss, pairwise_distances\n",
    "\n",
    "# Create random test tensors\n",
    "batch_size = 16\n",
    "z = torch.randn(batch_size, 4096)  # Simulated latents\n",
    "r = torch.randn(batch_size, 768)   # Simulated DINOv2 features\n",
    "\n",
    "# Test correlation loss\n",
    "loss_fn = MMRegLoss(variant='correlation')\n",
    "loss = loss_fn(z, r)\n",
    "print(f\"Correlation loss: {loss.item():.4f}\")\n",
    "\n",
    "# Test SI-MSE loss\n",
    "loss_fn_mse = MMRegLoss(variant='si_mse')\n",
    "loss_mse = loss_fn_mse(z, r)\n",
    "print(f\"SI-MSE loss: {loss_mse.item():.4f}\")\n",
    "\n",
    "print(\"\\n✓ Loss functions working!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Reference Model (DINOv2)\n",
    "from src.models.reference import DINOv2Reference\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Load DINOv2\n",
    "print(\"Loading DINOv2 (this may take a moment)...\")\n",
    "dino = DINOv2Reference(device=device)\n",
    "\n",
    "# Test with random images\n",
    "test_images = torch.randn(4, 3, 256, 256).to(device)\n",
    "test_images = (test_images - test_images.min()) / (test_images.max() - test_images.min())  # Normalize to [0,1]\n",
    "\n",
    "with torch.no_grad():\n",
    "    features = dino(test_images)\n",
    "\n",
    "print(f\"Input shape: {test_images.shape}\")\n",
    "print(f\"Output shape: {features.shape}\")\n",
    "print(\"\\n✓ DINOv2 reference model working!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test VAE Wrapper\n",
    "from src.models.vae_wrapper import load_vae\n",
    "\n",
    "print(\"Loading VAE (this may take a moment)...\")\n",
    "vae = load_vae(device=device, use_gradient_checkpointing=True)\n",
    "\n",
    "# Test forward pass\n",
    "test_images_vae = torch.randn(4, 3, 256, 256).to(device) * 2 - 1  # Range [-1, 1]\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = vae(test_images_vae)\n",
    "\n",
    "print(f\"Input shape: {test_images_vae.shape}\")\n",
    "print(f\"Latent shape: {outputs['latent'].shape}\")\n",
    "print(f\"Latent flat shape: {outputs['latent_flat'].shape}\")\n",
    "print(f\"Reconstruction shape: {outputs['x_recon'].shape}\")\n",
    "print(\"\\n✓ VAE wrapper working!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Full Loss Computation\n",
    "from src.models.losses import VAELoss\n",
    "\n",
    "# Create full loss function\n",
    "full_loss = VAELoss(lambda_mm=0.1, beta=1.0, mm_variant='correlation')\n",
    "\n",
    "# Forward pass\n",
    "with torch.no_grad():\n",
    "    outputs = vae(test_images_vae)\n",
    "    ref_features = dino(test_images_vae)\n",
    "\n",
    "# Compute loss (need gradients for this)\n",
    "vae.train()\n",
    "outputs = vae(test_images_vae)\n",
    "ref_features = dino(test_images_vae).detach()\n",
    "\n",
    "losses = full_loss(\n",
    "    x=test_images_vae,\n",
    "    x_recon=outputs['x_recon'],\n",
    "    z=outputs['latent_flat'],\n",
    "    r=ref_features,\n",
    "    posterior=outputs['posterior']\n",
    ")\n",
    "\n",
    "print(f\"Total loss: {losses['loss'].item():.4f}\")\n",
    "print(f\"Recon loss: {losses['recon_loss'].item():.4f}\")\n",
    "print(f\"KL loss: {losses['kl_loss'].item():.4f}\")\n",
    "print(f\"MM loss: {losses['mm_loss'].item():.4f}\")\n",
    "\n",
    "# Test backward\n",
    "losses['loss'].backward()\n",
    "print(\"\\n✓ Full loss and backward pass working!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Data Loading (Imagenette)\n",
    "from src.data.dataset import get_dataset_and_loader\n",
    "\n",
    "print(\"Loading Imagenette dataset...\")\n",
    "train_dataset, train_loader = get_dataset_and_loader(\n",
    "    dataset_name='imagenette',\n",
    "    root='./data',\n",
    "    split='train',\n",
    "    image_size=256,\n",
    "    batch_size=8,\n",
    "    num_workers=2\n",
    ")\n",
    "\n",
    "print(f\"Dataset size: {len(train_dataset)}\")\n",
    "\n",
    "# Get a batch\n",
    "images, labels = next(iter(train_loader))\n",
    "print(f\"Batch shape: {images.shape}\")\n",
    "print(f\"Labels: {labels}\")\n",
    "print(f\"Image range: [{images.min():.2f}, {images.max():.2f}]\")\n",
    "print(\"\\n✓ Data loading working!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize some samples\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(2, 4, figsize=(12, 6))\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    img = images[i].permute(1, 2, 0).numpy()\n",
    "    img = (img + 1) / 2  # Convert from [-1,1] to [0,1]\n",
    "    img = img.clip(0, 1)\n",
    "    ax.imshow(img)\n",
    "    ax.axis('off')\n",
    "    ax.set_title(f'Label: {labels[i].item()}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Quick Training Test\n",
    "\n",
    "Run a few iterations to make sure training works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick training test (few batches)\n",
    "from src.models.vae_wrapper import load_vae\n",
    "from src.models.reference import get_reference_model\n",
    "from src.models.losses import VAELoss\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "\n",
    "# Reload models fresh\n",
    "vae = load_vae(device=device)\n",
    "ref_model = get_reference_model('dinov2', device=device)\n",
    "loss_fn = VAELoss(lambda_mm=0.1)\n",
    "\n",
    "optimizer = torch.optim.AdamW(vae.parameters(), lr=1e-5)\n",
    "scaler = GradScaler()\n",
    "\n",
    "# Train for a few batches\n",
    "vae.train()\n",
    "num_test_batches = 5\n",
    "\n",
    "print(\"Running quick training test...\")\n",
    "for batch_idx, (images, _) in enumerate(train_loader):\n",
    "    if batch_idx >= num_test_batches:\n",
    "        break\n",
    "    \n",
    "    images = images.to(device)\n",
    "    \n",
    "    # Get reference\n",
    "    with torch.no_grad():\n",
    "        ref_features = ref_model(images)\n",
    "    \n",
    "    # Forward\n",
    "    optimizer.zero_grad()\n",
    "    with autocast():\n",
    "        outputs = vae(images)\n",
    "        losses = loss_fn(\n",
    "            x=images,\n",
    "            x_recon=outputs['x_recon'],\n",
    "            z=outputs['latent_flat'],\n",
    "            r=ref_features,\n",
    "            posterior=outputs['posterior']\n",
    "        )\n",
    "    \n",
    "    # Backward\n",
    "    scaler.scale(losses['loss']).backward()\n",
    "    scaler.step(optimizer)\n",
    "    scaler.update()\n",
    "    \n",
    "    print(f\"Batch {batch_idx+1}: loss={losses['loss'].item():.4f}, \"\n",
    "          f\"recon={losses['recon_loss'].item():.4f}, mm={losses['mm_loss'].item():.4f}\")\n",
    "\n",
    "print(\"\\n✓ Training loop working!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Full Training\n",
    "\n",
    "Now run the actual training. Choose baseline or MM-Reg."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "CONFIG = {\n",
    "    'experiment': 'mmreg',  # 'baseline' or 'mmreg'\n",
    "    'lambda_mm': 0.1,       # Only used for mmreg\n",
    "    'epochs': 5,\n",
    "    'batch_size': 32,       # Reduce if OOM\n",
    "    'learning_rate': 1e-5,\n",
    "    'image_size': 256,\n",
    "    'num_workers': 2,\n",
    "}\n",
    "\n",
    "print(f\"Configuration: {CONFIG}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup training\n",
    "from src.models.vae_wrapper import load_vae\n",
    "from src.models.reference import get_reference_model\n",
    "from src.models.losses import VAELoss\n",
    "from src.data.dataset import get_dataset_and_loader\n",
    "from src.trainer import MMRegTrainer\n",
    "\n",
    "# Load models\n",
    "print(\"Loading models...\")\n",
    "vae = load_vae(device=device)\n",
    "ref_model = get_reference_model('dinov2', device=device)\n",
    "\n",
    "# Loss function\n",
    "lambda_mm = CONFIG['lambda_mm'] if CONFIG['experiment'] == 'mmreg' else 0.0\n",
    "loss_fn = VAELoss(lambda_mm=lambda_mm)\n",
    "\n",
    "# Data\n",
    "print(\"Loading data...\")\n",
    "train_dataset, train_loader = get_dataset_and_loader(\n",
    "    dataset_name='imagenette',\n",
    "    root='./data',\n",
    "    split='train',\n",
    "    image_size=CONFIG['image_size'],\n",
    "    batch_size=CONFIG['batch_size'],\n",
    "    num_workers=CONFIG['num_workers']\n",
    ")\n",
    "\n",
    "val_dataset, val_loader = get_dataset_and_loader(\n",
    "    dataset_name='imagenette',\n",
    "    root='./data',\n",
    "    split='val',\n",
    "    image_size=CONFIG['image_size'],\n",
    "    batch_size=CONFIG['batch_size'],\n",
    "    num_workers=CONFIG['num_workers']\n",
    ")\n",
    "\n",
    "print(f\"Train: {len(train_dataset)}, Val: {len(val_dataset)}\")\n",
    "\n",
    "# Optimizer\n",
    "optimizer = torch.optim.AdamW(vae.parameters(), lr=CONFIG['learning_rate'])\n",
    "\n",
    "# Trainer\n",
    "save_dir = f\"./checkpoints/{CONFIG['experiment']}\"\n",
    "trainer = MMRegTrainer(\n",
    "    vae=vae,\n",
    "    reference_model=ref_model,\n",
    "    loss_fn=loss_fn,\n",
    "    optimizer=optimizer,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    device=device,\n",
    "    save_dir=save_dir\n",
    ")\n",
    "\n",
    "print(f\"\\nReady to train {CONFIG['experiment']} for {CONFIG['epochs']} epochs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run training\n",
    "trainer.train(num_epochs=CONFIG['epochs'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate geometric metrics\n",
    "from src.analysis.evaluate_geometry import full_evaluation\n",
    "\n",
    "# Load best checkpoint\n",
    "checkpoint = torch.load(f\"{save_dir}/best.pt\")\n",
    "vae.load_state_dict(checkpoint['vae_state_dict'])\n",
    "\n",
    "# Run evaluation\n",
    "results = full_evaluation(\n",
    "    vae=vae,\n",
    "    reference_model=ref_model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    num_classes=10,  # Imagenette has 10 classes\n",
    "    device=device\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"FINAL RESULTS\")\n",
    "print(\"=\"*50)\n",
    "for key, value in results.items():\n",
    "    print(f\"{key}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize reconstructions\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "vae.eval()\n",
    "images, _ = next(iter(val_loader))\n",
    "images = images[:8].to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = vae(images, sample=False)\n",
    "    recon = outputs['x_recon']\n",
    "\n",
    "# Plot\n",
    "fig, axes = plt.subplots(2, 8, figsize=(16, 4))\n",
    "\n",
    "for i in range(8):\n",
    "    # Original\n",
    "    img = images[i].cpu().permute(1, 2, 0).numpy()\n",
    "    img = ((img + 1) / 2).clip(0, 1)\n",
    "    axes[0, i].imshow(img)\n",
    "    axes[0, i].axis('off')\n",
    "    if i == 0:\n",
    "        axes[0, i].set_title('Original')\n",
    "    \n",
    "    # Reconstruction\n",
    "    rec = recon[i].cpu().permute(1, 2, 0).numpy()\n",
    "    rec = ((rec + 1) / 2).clip(0, 1)\n",
    "    axes[1, i].imshow(rec)\n",
    "    axes[1, i].axis('off')\n",
    "    if i == 0:\n",
    "        axes[1, i].set_title('Reconstruction')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{save_dir}/reconstructions.png\", dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training curves\n",
    "import json\n",
    "\n",
    "with open(f\"{save_dir}/history.json\", 'r') as f:\n",
    "    history = json.load(f)\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "# Total loss\n",
    "axes[0].plot([h['loss'] for h in history['train']], label='Train')\n",
    "axes[0].plot([h['loss'] for h in history['val']], label='Val')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Total Loss')\n",
    "axes[0].legend()\n",
    "axes[0].set_title('Total Loss')\n",
    "\n",
    "# Reconstruction loss\n",
    "axes[1].plot([h['recon_loss'] for h in history['train']], label='Train')\n",
    "axes[1].plot([h['recon_loss'] for h in history['val']], label='Val')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Recon Loss')\n",
    "axes[1].legend()\n",
    "axes[1].set_title('Reconstruction Loss')\n",
    "\n",
    "# MM loss\n",
    "axes[2].plot([h['mm_loss'] for h in history['train']], label='Train')\n",
    "axes[2].plot([h['mm_loss'] for h in history['val']], label='Val')\n",
    "axes[2].set_xlabel('Epoch')\n",
    "axes[2].set_ylabel('MM Loss')\n",
    "axes[2].legend()\n",
    "axes[2].set_title('MM-Reg Loss')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{save_dir}/training_curves.png\", dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Save Results\n",
    "\n",
    "Save the results for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save final results\n",
    "import json\n",
    "\n",
    "final_results = {\n",
    "    'config': CONFIG,\n",
    "    'metrics': results\n",
    "}\n",
    "\n",
    "with open(f\"{save_dir}/final_results.json\", 'w') as f:\n",
    "    json.dump(final_results, f, indent=2)\n",
    "\n",
    "print(f\"Results saved to {save_dir}/final_results.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
