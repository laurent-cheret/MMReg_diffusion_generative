{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MM-Reg: Manifold-Matching Regularization for VAE\n",
    "\n",
    "This notebook implements MM-Reg with **pre-computed PCA embeddings**.\n",
    "\n",
    "**Key insight**: Pre-compute PCA projections for ALL training samples. During training, each batch looks up its corresponding PCA embeddings and compares pairwise distances.\n",
    "\n",
    "**Steps:**\n",
    "1. Setup & Install\n",
    "2. Download data & Pre-compute PCA embeddings\n",
    "3. Train MM-Reg VAE\n",
    "4. Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone repository\n",
    "!git clone https://github.com/laurent-cheret/MMReg_diffusion_generative.git\n",
    "%cd MMReg_diffusion_generative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install -q torch torchvision diffusers transformers accelerate\n",
    "!pip install -q pyyaml tqdm scipy scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '.')\n",
    "\n",
    "import torch\n",
    "import os\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"Device: {device}\")\n",
    "if device == 'cuda':\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Pre-compute PCA Embeddings\n",
    "\n",
    "This is the key step: compute PCA projections for ALL training samples using **fixed transforms** (no augmentation). These embeddings define the reference manifold structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.dataset import (\n",
    "    get_imagenette_dataset, \n",
    "    compute_pca_embeddings,\n",
    "    get_dataset_and_loader\n",
    ")\n",
    "\n",
    "# Configuration\n",
    "DATA_ROOT = './data'\n",
    "IMAGE_SIZE = 256\n",
    "PCA_COMPONENTS = 256  # Dimensionality of reference space\n",
    "\n",
    "# Load dataset with FIXED transforms (deterministic, no augmentation)\n",
    "print(\"Loading Imagenette with fixed transforms...\")\n",
    "train_dataset_fixed = get_imagenette_dataset(\n",
    "    root=DATA_ROOT,\n",
    "    split='train',\n",
    "    image_size=IMAGE_SIZE,\n",
    "    fixed_transform=True  # Important: no random augmentation\n",
    ")\n",
    "\n",
    "val_dataset_fixed = get_imagenette_dataset(\n",
    "    root=DATA_ROOT,\n",
    "    split='val',\n",
    "    image_size=IMAGE_SIZE,\n",
    "    fixed_transform=True\n",
    ")\n",
    "\n",
    "print(f\"Train samples: {len(train_dataset_fixed)}\")\n",
    "print(f\"Val samples: {len(val_dataset_fixed)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute PCA embeddings (this takes a few minutes)\n",
    "os.makedirs('./embeddings', exist_ok=True)\n",
    "\n",
    "print(\"\\nComputing PCA embeddings for training set...\")\n",
    "train_pca = compute_pca_embeddings(\n",
    "    train_dataset_fixed,\n",
    "    n_components=PCA_COMPONENTS,\n",
    "    batch_size=64\n",
    ")\n",
    "torch.save(train_pca, './embeddings/train_pca.pt')\n",
    "\n",
    "print(\"\\nComputing PCA embeddings for validation set...\")\n",
    "val_pca = compute_pca_embeddings(\n",
    "    val_dataset_fixed,\n",
    "    n_components=PCA_COMPONENTS,\n",
    "    batch_size=64\n",
    ")\n",
    "torch.save(val_pca, './embeddings/val_pca.pt')\n",
    "\n",
    "print(f\"\\nâœ“ PCA embeddings saved!\")\n",
    "print(f\"  Train: {train_pca.shape}\")\n",
    "print(f\"  Val: {val_pca.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train MM-Reg VAE\n",
    "\n",
    "Now train with pre-computed PCA embeddings. The dataloader returns `(image, label, pca_embedding)` tuples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training configuration\n",
    "CONFIG = {\n",
    "    'experiment': 'mmreg_pca',\n",
    "    'lambda_mm': 1.0,      # MM-Reg weight (losses are now properly scaled)\n",
    "    'beta': 1e-6,          # KL weight (very small, KL is ~70k unscaled)\n",
    "    'epochs': 5,\n",
    "    'batch_size': 32,\n",
    "    'learning_rate': 1e-5,\n",
    "    'image_size': 256,\n",
    "}\n",
    "\n",
    "print(\"Configuration:\")\n",
    "for k, v in CONFIG.items():\n",
    "    print(f\"  {k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.vae_wrapper import load_vae\n",
    "from src.models.losses import VAELoss\n",
    "from src.trainer import MMRegTrainer\n",
    "\n",
    "# Load VAE\n",
    "print(\"Loading VAE...\")\n",
    "vae = load_vae(device=device)\n",
    "\n",
    "# Loss function with proper scaling\n",
    "loss_fn = VAELoss(\n",
    "    lambda_mm=CONFIG['lambda_mm'],\n",
    "    beta=CONFIG['beta'],\n",
    "    mm_variant='correlation'\n",
    ")\n",
    "\n",
    "print(f\"Loss weights: lambda_mm={loss_fn.lambda_mm}, beta={loss_fn.beta}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data WITH pre-computed PCA embeddings\n",
    "print(\"Loading data with PCA embeddings...\")\n",
    "\n",
    "train_dataset, train_loader = get_dataset_and_loader(\n",
    "    dataset_name='imagenette',\n",
    "    root=DATA_ROOT,\n",
    "    split='train',\n",
    "    image_size=CONFIG['image_size'],\n",
    "    batch_size=CONFIG['batch_size'],\n",
    "    num_workers=2,\n",
    "    pca_embeddings_path='./embeddings/train_pca.pt'  # Pre-computed PCA!\n",
    ")\n",
    "\n",
    "val_dataset, val_loader = get_dataset_and_loader(\n",
    "    dataset_name='imagenette',\n",
    "    root=DATA_ROOT,\n",
    "    split='val',\n",
    "    image_size=CONFIG['image_size'],\n",
    "    batch_size=CONFIG['batch_size'],\n",
    "    num_workers=2,\n",
    "    pca_embeddings_path='./embeddings/val_pca.pt'\n",
    ")\n",
    "\n",
    "# Verify the dataloader returns 3 items\n",
    "batch = next(iter(train_loader))\n",
    "print(f\"Batch contents: {len(batch)} items\")\n",
    "print(f\"  Images: {batch[0].shape}\")\n",
    "print(f\"  Labels: {batch[1].shape}\")\n",
    "print(f\"  PCA embeddings: {batch[2].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup trainer\n",
    "optimizer = torch.optim.AdamW(vae.parameters(), lr=CONFIG['learning_rate'])\n",
    "\n",
    "save_dir = f\"./checkpoints/{CONFIG['experiment']}\"\n",
    "trainer = MMRegTrainer(\n",
    "    vae=vae,\n",
    "    loss_fn=loss_fn,\n",
    "    optimizer=optimizer,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    reference_model=None,  # Not needed - using pre-computed PCA!\n",
    "    device=device,\n",
    "    save_dir=save_dir\n",
    ")\n",
    "\n",
    "print(f\"\\nReady to train for {CONFIG['epochs']} epochs\")\n",
    "print(f\"Checkpoints will be saved to: {save_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train!\n",
    "trainer.train(num_epochs=CONFIG['epochs'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training curves\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "\n",
    "with open(f\"{save_dir}/history.json\", 'r') as f:\n",
    "    history = json.load(f)\n",
    "\n",
    "fig, axes = plt.subplots(1, 4, figsize=(16, 4))\n",
    "\n",
    "metrics = ['loss', 'recon_loss', 'kl_loss', 'mm_loss']\n",
    "titles = ['Total Loss', 'Reconstruction', 'KL Divergence', 'MM-Reg Loss']\n",
    "\n",
    "for ax, metric, title in zip(axes, metrics, titles):\n",
    "    ax.plot([h[metric] for h in history['train']], label='Train', marker='o')\n",
    "    ax.plot([h[metric] for h in history['val']], label='Val', marker='s')\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.set_ylabel(metric)\n",
    "    ax.set_title(title)\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{save_dir}/training_curves.png\", dpi=150)\n",
    "plt.show()\n",
    "\n",
    "# Print final metrics\n",
    "print(\"\\nFinal metrics:\")\n",
    "print(f\"  Train - loss: {history['train'][-1]['loss']:.4f}, mm_loss: {history['train'][-1]['mm_loss']:.4f}\")\n",
    "print(f\"  Val   - loss: {history['val'][-1]['loss']:.4f}, mm_loss: {history['val'][-1]['mm_loss']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize reconstructions\n",
    "vae.eval()\n",
    "batch = next(iter(val_loader))\n",
    "images = batch[0][:8].to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = vae(images, sample=False)\n",
    "    recon = outputs['x_recon']\n",
    "\n",
    "fig, axes = plt.subplots(2, 8, figsize=(16, 4))\n",
    "\n",
    "for i in range(8):\n",
    "    # Original\n",
    "    img = images[i].cpu().permute(1, 2, 0).numpy()\n",
    "    img = ((img + 1) / 2).clip(0, 1)\n",
    "    axes[0, i].imshow(img)\n",
    "    axes[0, i].axis('off')\n",
    "    \n",
    "    # Reconstruction\n",
    "    rec = recon[i].cpu().permute(1, 2, 0).numpy()\n",
    "    rec = ((rec + 1) / 2).clip(0, 1)\n",
    "    axes[1, i].imshow(rec)\n",
    "    axes[1, i].axis('off')\n",
    "\n",
    "axes[0, 0].set_title('Original', fontsize=12)\n",
    "axes[1, 0].set_title('Reconstruction', fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{save_dir}/reconstructions.png\", dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate distance correlation\n",
    "from src.analysis.evaluate_geometry import compute_distance_correlation\n",
    "from src.models.reference import PCAReference\n",
    "\n",
    "# Create a simple PCA reference that uses the pre-computed embeddings\n",
    "# For evaluation, we just need the correlation between latent and PCA distances\n",
    "\n",
    "print(\"Computing distance correlation...\")\n",
    "\n",
    "# Get a subset of samples\n",
    "all_latents = []\n",
    "all_pca = []\n",
    "\n",
    "vae.eval()\n",
    "with torch.no_grad():\n",
    "    for batch in val_loader:\n",
    "        images, _, pca_emb = batch\n",
    "        images = images.to(device)\n",
    "        \n",
    "        outputs = vae(images, sample=False)\n",
    "        all_latents.append(outputs['latent_flat'].cpu())\n",
    "        all_pca.append(pca_emb)\n",
    "\n",
    "all_latents = torch.cat(all_latents, dim=0)\n",
    "all_pca = torch.cat(all_pca, dim=0)\n",
    "\n",
    "print(f\"Latents shape: {all_latents.shape}\")\n",
    "print(f\"PCA shape: {all_pca.shape}\")\n",
    "\n",
    "# Compute pairwise distances and correlation\n",
    "from src.models.losses import pairwise_distances, get_upper_triangular\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "\n",
    "# Use subset for speed\n",
    "n_samples = min(500, len(all_latents))\n",
    "D_latent = pairwise_distances(all_latents[:n_samples])\n",
    "D_pca = pairwise_distances(all_pca[:n_samples])\n",
    "\n",
    "d_latent = get_upper_triangular(D_latent).numpy()\n",
    "d_pca = get_upper_triangular(D_pca).numpy()\n",
    "\n",
    "pearson, _ = pearsonr(d_latent, d_pca)\n",
    "spearman, _ = spearmanr(d_latent, d_pca)\n",
    "\n",
    "print(f\"\\n=== Distance Correlation ===\")\n",
    "print(f\"Pearson:  {pearson:.4f}\")\n",
    "print(f\"Spearman: {spearman:.4f}\")\n",
    "print(f\"\\nTarget: > 0.5 indicates geometry is being preserved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results\n",
    "results = {\n",
    "    'config': CONFIG,\n",
    "    'final_train_loss': history['train'][-1]['loss'],\n",
    "    'final_val_loss': history['val'][-1]['loss'],\n",
    "    'final_mm_loss': history['val'][-1]['mm_loss'],\n",
    "    'pearson_correlation': float(pearson),\n",
    "    'spearman_correlation': float(spearman)\n",
    "}\n",
    "\n",
    "with open(f\"{save_dir}/results.json\", 'w') as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "\n",
    "print(f\"Results saved to {save_dir}/results.json\")\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"SUMMARY\")\n",
    "print(\"=\"*50)\n",
    "for k, v in results.items():\n",
    "    if isinstance(v, float):\n",
    "        print(f\"{k}: {v:.4f}\")\n",
    "    else:\n",
    "        print(f\"{k}: {v}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
